@misc{cool_data_project,
  author       = {Dominković, Dominik Franjo and Bergaentzlé, Claire Marie and Englmair, Gerald and Furbo, Simon and Madsen, Henrik and Junker, Rune Grønborg and Brok, Niclas Brabrand and Stefansen, Rikke and Kokkegård, Hanne},
  title        = {Cool-Data: Flexible Cooling of Data Centers},
  howpublished = {\url{https://orbit.dtu.dk/en/projects/flexible-cooling-of-data-centers}},
  note         = {Accessed: December 2024}
}


@misc{gminsights_data_center_growth,
  title        = {Data Center Infrastructure Market Analysis},
  howpublished = {\url{https://www.gminsights.com/industry-analysis/data-center-infrastructure-market}},
  note         = {Accessed: December 2024}
}

@misc{brightlio_data_center_stats,
  title        = {Data Center Stats},
  howpublished = {\url{https://brightlio.com/data-center-stats/}},
  note         = {Accessed: December 2024}
}

@misc{deepmind_cooling,
  author       = {Richard Evans and Jim Gao},
  title        = {DeepMind AI Reduces Google Data Centre Cooling Bill by 40\%},
  howpublished = {\url{https://deepmind.google/discover/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40/}},
  note         = {Accessed: December 2024},
  year         = {2016}
}

@misc{energyplus,
  title        = {EnergyPlus: Building Energy Simulation Software},
  howpublished = {\url{https://energyplus.net/}},
  note         = {Accessed: December 2024}
}

@misc{sinergym_github,
  author       = {UGR-SAIL},
  title        = {Sinergym: A Reinforcement Learning Framework for EnergyPlus},
  howpublished = {\url{https://github.com/ugr-sail/sinergym}},
  note         = {Accessed: December 2024}
}
@article{wang2016dueling,
  title={Dueling Network Architectures for Deep Reinforcement Learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and van Hasselt, Hado and Lanctot, Marc and de Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2016},
  url={https://arxiv.org/pdf/1511.06581}
}

@article{zhang2019building,
  author       = {Chi Zhang and Sanmukh R. Kuppannagari and Rajgopal Kannan and Viktor K. Prasanna},
  title        = {Building HVAC Scheduling Using Reinforcement Learning via Neural Network Based Model Approximation},
  journal      = {arXiv preprint arXiv:1910.05313},
  year         = {2019},
  url          = {https://arxiv.org/abs/1910.05313}
}

@inproceedings{song2021comparison,
  author       = {H. Francis Song and Abbas Abdolmaleki and Jost Tobias Springenberg and Aidan Clark and Hubert Soyer and Jack W. Rae and Seb Noury and Arun Ahuja and Siqi Liu and Dhruva Tirumala and Nicolas Heess and Dan Belov and Martin Riedmiller and Matthew M. Botvinick},
  title        = {Comparison of Deep Reinforcement Learning Algorithms in Data Center Cooling Management: A Case Study},
  booktitle    = {Proceedings of the IEEE Conference},
  year         = {2021},
  url          = {https://ieeexplore.ieee.org/document/9659100}
}

@inproceedings{cool_ai_framework,
  author       = {qatshana},
  title        = {Cool.AI: A Reinforcement Learning Framework for Data Center Cooling Optimization},
  booktitle    = {Proceedings of the IEEE Conference},
  year         = {2023},
  url          = {https://ieeexplore.ieee.org/document/9935071}
}

@misc{sinergym_paper,
  author       = {Antonio Manjavacas and Alejandro Campoy-Nieves and Javier Jiménez-Raboso and Miguel Molina-Solana and Juan Gómez-Romero},
  title        = {An Experimental Evaluation of Deep Reinforcement Learning Algorithms for HVAC Control},
  howpublished = {\url{https://arxiv.org/pdf/2401.05737}},
  year         = {2024},
  note         = {Accessed: December 2024}
}


@article{mpo_paper,
  title = {Maximum a Posteriori Policy Optimization},
  author = {Abdolmaleki, Abbas and others},
  journal = {Arxiv},
  year = {2018},
  url = {https://arxiv.org/pdf/1806.06920}
}

@misc{vmpo_paper,
      title={V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control}, 
      author={H. Francis Song and Abbas Abdolmaleki and Jost Tobias Springenberg and Aidan Clark and Hubert Soyer and Jack W. Rae and Seb Noury and Arun Ahuja and Siqi Liu and Dhruva Tirumala and Nicolas Heess and Dan Belov and Martin Riedmiller and Matthew M. Botvinick},
      year={2019},
      eprint={1909.12238},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1909.12238}, 
}

@misc{sac_paper,
      title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
      author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
      year={2018},
      eprint={1801.01290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1801.01290}, 
}

@inproceedings{sac_comparitive_paper,
author = {Cao, Zhiwei and Wang, Ruihang and Zhou, Xin and Wen, Yonggang},
title = {Toward Model-Assisted Safe Reinforcement Learning for Data Center Cooling Control: A Lyapunov-based Approach},
year = {2023},
isbn = {9798400700323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575813.3597343},
doi = {10.1145/3575813.3597343},
abstract = {This paper considers intelligent data center cooling control via the Deep Reinforcement Learning (DRL) approach to improve data center sustainability. Existing DRL-based controllers are trained with a simplified data hall thermodynamic model which assumes uniform room temperature distribution. This assumption is not valid for a real-world data center with highly nonuniform temperature distribution. Furthermore, most of them cannot guarantee thermal safety during the DRL learning process. To bridge these gaps, we propose LyaSafe, a model-assisted safe DRL approach for data center cooling control. To address the safety evaluation issue, we develop a coupled model that combines a differentiable surrogate data hall thermodynamics model with the energy model. It can simulate both data hall temperature distribution and the facility energy consumption. To address safe learning, we introduce a novel constrained Markov Decision Process (CMDP) formulation for data center cooling control by considering the Rack Cooling Index (RCI), the best-practice metric for evaluating compliance with ASHRAE data center thermal guidelines. The objective is to minimize data center carbon footprints while regulating the RCI within a threshold. We first derive the safety set based on the concept of the virtual queue and Lyapunov stability theory. Next, we rectify unsafe actions from the DRL agent by projecting them to the safety set. We evaluate LyaSafe in a data center hosting 20 racks and 299 servers. Evaluation results show that LyaSafe can ensure strict safety during the DRL learning while achieving up to 50 metric tons of annual carbon emission savings using Singapore’s statistics. Moreover, we conduct root cause analysis for the savings, revealing the importance of joint control of the data hall and the chiller plant.},
booktitle = {Proceedings of the 14th ACM International Conference on Future Energy Systems},
pages = {333–346},
numpages = {14},
keywords = {Data center, Lyapunov stability theory, cooling control, safe reinforcement learning},
location = {Orlando, FL, USA},
series = {e-Energy '23}
}

@INPROCEEDINGS{deepee,
  author={Ran, Yongyi and Hu, Han and Zhou, Xin and Wen, Yonggang},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={DeepEE: Joint Optimization of Job Scheduling and Cooling Control for Data Center Energy Efficiency Using Deep Reinforcement Learning}, 
  year={2019},
  volume={},
  number={},
  pages={645-655},
  keywords={Cooling;Data centers;Optimization;Task analysis;Servers;Aerospace electronics;Temperature distribution;Deep reinforcement learning;Data center;Energy efficiency;Job scheduling;Cooling control},
  doi={10.1109/ICDCS.2019.00070}}

@article{schulman2015high,
  title={High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015},
  url={https://arxiv.org/abs/1506.02438}
}
@article{peng2018deepmimic,
  title={DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills},
  author={Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={4},
  pages={143:1--143:14},
  year={2018},
  publisher={ACM},
  doi={10.1145/3197517.3201311},
  url={https://arxiv.org/pdf/1804.02717}
}
